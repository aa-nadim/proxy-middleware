w3e12@w3e12:~/Desktop/a-11/assignment$ python3 --version
Python 3.12.3
w3e12@w3e12:~/Desktop/a-11/assignment$ mkdir scrapy-assignment
w3e12@w3e12:~/Desktop/a-11/assignment$ ls
help.txt  my_scraper.egg-info  scrapy-assignment  task.md
w3e12@w3e12:~/Desktop/a-11/assignment$ cd scrapy-assignment/
w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ ls
w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ python3 -m venv env
w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ source env/bin/activate
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ ls
env
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ pip install scrapy
Collecting scrapy
  Using cached Scrapy-2.12.0-py2.py3-none-any.whl.metadata (5.3 kB)
Collecting Twisted>=21.7.0 (from scrapy)
  Using cached twisted-24.11.0-py3-none-any.whl.metadata (20 kB)
Collecting cryptography>=37.0.0 (from scrapy)
  Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)
Collecting cssselect>=0.9.1 (from scrapy)
  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)
Collecting itemloaders>=1.0.1 (from scrapy)
  Using cached itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)
Collecting parsel>=1.5.0 (from scrapy)
  Using cached parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)
Collecting pyOpenSSL>=22.0.0 (from scrapy)
  Using cached pyOpenSSL-24.3.0-py3-none-any.whl.metadata (15 kB)
Collecting queuelib>=1.4.2 (from scrapy)
  Using cached queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)
Collecting service-identity>=18.1.0 (from scrapy)
  Using cached service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)
Collecting w3lib>=1.17.0 (from scrapy)
  Using cached w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)
Collecting zope.interface>=5.1.0 (from scrapy)
  Using cached zope.interface-7.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)
Collecting protego>=0.1.15 (from scrapy)
  Using cached Protego-0.3.1-py2.py3-none-any.whl.metadata (5.9 kB)
Collecting itemadapter>=0.1.0 (from scrapy)
  Using cached itemadapter-0.10.0-py3-none-any.whl.metadata (18 kB)
Collecting packaging (from scrapy)
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting tldextract (from scrapy)
  Using cached tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)
Collecting lxml>=4.6.0 (from scrapy)
  Using cached lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)
Collecting defusedxml>=0.7.1 (from scrapy)
  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)
Collecting PyDispatcher>=2.0.5 (from scrapy)
  Using cached PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)
Collecting cffi>=1.12 (from cryptography>=37.0.0->scrapy)
  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)
  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)
Collecting attrs>=19.1.0 (from service-identity>=18.1.0->scrapy)
  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)
Collecting pyasn1 (from service-identity>=18.1.0->scrapy)
  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)
Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)
  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)
Collecting automat>=24.8.0 (from Twisted>=21.7.0->scrapy)
  Using cached Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)
Collecting constantly>=15.1 (from Twisted>=21.7.0->scrapy)
  Using cached constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)
Collecting hyperlink>=17.1.1 (from Twisted>=21.7.0->scrapy)
  Using cached hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)
Collecting incremental>=24.7.0 (from Twisted>=21.7.0->scrapy)
  Using cached incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)
Collecting typing-extensions>=4.2.0 (from Twisted>=21.7.0->scrapy)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting setuptools (from zope.interface>=5.1.0->scrapy)
  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)
Collecting idna (from tldextract->scrapy)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting requests>=2.1.0 (from tldextract->scrapy)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting requests-file>=1.4 (from tldextract->scrapy)
  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting filelock>=3.0.8 (from tldextract->scrapy)
  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting pycparser (from cffi>=1.12->cryptography>=37.0.0->scrapy)
  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)
Collecting charset-normalizer<4,>=2 (from requests>=2.1.0->tldextract->scrapy)
  Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
Collecting urllib3<3,>=1.21.1 (from requests>=2.1.0->tldextract->scrapy)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests>=2.1.0->tldextract->scrapy)
  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)
Using cached Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)
Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)
Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)
Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)
Using cached itemadapter-0.10.0-py3-none-any.whl (11 kB)
Using cached itemloaders-1.3.2-py3-none-any.whl (12 kB)
Using cached lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)
Using cached parsel-1.9.1-py2.py3-none-any.whl (17 kB)
Using cached Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)
Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)
Using cached pyOpenSSL-24.3.0-py3-none-any.whl (56 kB)
Using cached queuelib-1.7.0-py2.py3-none-any.whl (13 kB)
Using cached service_identity-24.2.0-py3-none-any.whl (11 kB)
Using cached twisted-24.11.0-py3-none-any.whl (3.2 MB)
Using cached w3lib-2.2.1-py3-none-any.whl (21 kB)
Using cached zope.interface-7.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Using cached tldextract-5.1.3-py3-none-any.whl (104 kB)
Using cached attrs-24.3.0-py3-none-any.whl (63 kB)
Using cached Automat-24.8.1-py3-none-any.whl (42 kB)
Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)
Using cached constantly-23.10.4-py3-none-any.whl (13 kB)
Using cached filelock-3.16.1-py3-none-any.whl (16 kB)
Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached incremental-24.7.2-py3-none-any.whl (20 kB)
Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)
Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)
Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)
Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)
Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Using cached pycparser-2.22-py3-none-any.whl (117 kB)
Installing collected packages: PyDispatcher, w3lib, urllib3, typing-extensions, setuptools, queuelib, pycparser, pyasn1, protego, packaging, lxml, jmespath, itemadapter, idna, filelock, defusedxml, cssselect, constantly, charset-normalizer, certifi, automat, attrs, zope.interface, requests, pyasn1-modules, parsel, incremental, hyperlink, cffi, Twisted, requests-file, itemloaders, cryptography, tldextract, service-identity, pyOpenSSL, scrapy
Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 attrs-24.3.0 automat-24.8.1 certifi-2024.12.14 cffi-1.17.1 charset-normalizer-3.4.1 constantly-23.10.4 cryptography-44.0.0 cssselect-1.2.0 defusedxml-0.7.1 filelock-3.16.1 hyperlink-21.0.0 idna-3.10 incremental-24.7.2 itemadapter-0.10.0 itemloaders-1.3.2 jmespath-1.0.1 lxml-5.3.0 packaging-24.2 parsel-1.9.1 protego-0.3.1 pyOpenSSL-24.3.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 queuelib-1.7.0 requests-2.32.3 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 setuptools-75.6.0 tldextract-5.1.3 typing-extensions-4.12.2 urllib3-2.3.0 w3lib-2.2.1 zope.interface-7.2
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ scrapy
Scrapy 2.12.0 - no active project

Usage:
  scrapy <command> [options] [args]

Available commands:
  bench         Run quick benchmark test
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  runspider     Run a self-contained spider (without creating a project)
  settings      Get settings values
  shell         Interactive scraping console
  startproject  Create new project
  version       Print Scrapy version
  view          Open URL in browser, as seen by Scrapy

  [ more ]      More commands available when run from project directory

Use "scrapy <command> -h" to see more info about a command
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ ls
env
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ scrapy startproject my_scraper
New Scrapy project 'my_scraper', using template directory '/home/w3e12/Desktop/a-11/assignment/scrapy-assignment/env/lib/python3.12/site-packages/scrapy/templates/project', created in:
    /home/w3e12/Desktop/a-11/assignment/scrapy-assignment/my_scraper

You can start your first spider with:
    cd my_scraper
    scrapy genspider example example.com
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment$ cd my_scraper
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment/my_scraper$ code .
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment/my_scraper$ scrapy genspider scraper https://www.scrapingcourse.com/ecommerce/
Created spider 'scraper' using template 'basic' in module:
  my_scraper.spiders.scraper
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment/my_scraper$ scrapy crawl scraper
2025-01-03 12:25:19 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: my_scraper)
2025-01-03 12:25:19 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Linux-6.8.0-51-generic-x86_64-with-glibc2.39
2025-01-03 12:25:19 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-03 12:25:19 [asyncio] DEBUG: Using selector: EpollSelector
2025-01-03 12:25:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-03 12:25:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-03 12:25:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-03 12:25:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-03 12:25:19 [scrapy.extensions.telnet] INFO: Telnet Password: b6c0edbe24cc11c3
2025-01-03 12:25:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-03 12:25:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'my_scraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'my_scraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['my_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-03 12:25:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-03 12:25:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-03 12:25:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-01-03 12:25:19 [scrapy.core.engine] INFO: Spider opened
2025-01-03 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-03 12:25:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-03 12:25:20 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443
2025-01-03 12:25:20 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 "GET /list/public_suffix_list.dat HTTP/1.1" 200 86284
2025-01-03 12:25:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.scrapingcourse.com/robots.txt> (referer: None)
2025-01-03 12:25:21 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.scrapingcourse.com/ecommerce/>
2025-01-03 12:25:21 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-03 12:25:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'downloader/request_bytes': 233,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 1307,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.820378,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 3, 6, 25, 21, 292120, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'memusage/max': 66715648,
 'memusage/startup': 66715648,
 'response_received_count': 1,
 'responses_per_minute': None,
 'robotstxt/forbidden': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 3, 6, 25, 19, 471742, tzinfo=datetime.timezone.utc)}
2025-01-03 12:25:21 [scrapy.core.engine] INFO: Spider closed (finished)
(env) w3e12@w3e12:~/Desktop/a-11/assignment/scrapy-assignment/my_scraper$ 